# <class 'v1.Lexer.Components.Phrase.Phrase.LexResult'>
data: # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
  data:
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: False
        token: "Word Token"
        value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
          match: "<_sre.SRE_Match object; span=(123, 126), match='ten'>"
      phrase: "Word Token"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: False
        token: "Colon"
        value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
          match: "<_sre.SRE_Match object; span=(126, 127), match=':'>"
      phrase: "Colon"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
      is_ignored: True
      token: "HorizontalWhitespace"
      value: # <class 'v1.Lexer.Components.Tokens.HorizontalWhitespaceToken.MatchResult'>
        range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
          begin: 127
          end: 139
    - # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
      is_ignored: True
      token: "<comment>"
      value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
        match: "<_sre.SRE_Match object; span=(139, 151), match='# Comment 10'>"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: False
        token: "Newline+"
        value: # <class 'v1.Lexer.Components.Tokens.NewlineToken.MatchResult'>
          range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
            begin: 151
            end: 152
      phrase: "Newline+"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: False
        token: "Indent"
        value: # <class 'v1.Lexer.Components.Tokens.IndentToken.MatchResult'>
          indent_value: 4
          range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
            begin: 152
            end: 156
      phrase: "Indent"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data:
        - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
          data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
            is_ignored: False
            token: "Upper Token"
            value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
              match: "<_sre.SRE_Match object; span=(156, 162), match='ELEVEN'>"
          phrase: "Upper Token"
        - # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
          is_ignored: True
          token: "HorizontalWhitespace"
          value: # <class 'v1.Lexer.Components.Tokens.HorizontalWhitespaceToken.MatchResult'>
            range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
              begin: 162
              end: 168
        - # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
          is_ignored: True
          token: "<comment>"
          value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
            match: "<_sre.SRE_Match object; span=(168, 180), match='# Comment 11'>"
        - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
          data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
            is_ignored: False
            token: "Newline+"
            value: # <class 'v1.Lexer.Components.Tokens.NewlineToken.MatchResult'>
              range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
                begin: 180
                end: 181
          phrase: "Newline+"
      phrase: "[Upper Token, Newline+]"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data:
        - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
          data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
            is_ignored: False
            token: "Number Token"
            value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
              match: "<_sre.SRE_Match object; span=(185, 187), match='12'>"
          phrase: "Number Token"
        - # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
          is_ignored: True
          token: "HorizontalWhitespace"
          value: # <class 'v1.Lexer.Components.Tokens.HorizontalWhitespaceToken.MatchResult'>
            range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
              begin: 187
              end: 197
        - # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
          is_ignored: True
          token: "<comment>"
          value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
            match: "<_sre.SRE_Match object; span=(197, 209), match='# Comment 12'>"
        - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
          data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
            is_ignored: False
            token: "Newline+"
            value: # <class 'v1.Lexer.Components.Tokens.NewlineToken.MatchResult'>
              range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
                begin: 209
                end: 210
          phrase: "Newline+"
      phrase: "[Number Token, Newline+]"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: False
        token: "Dedent"
        value: # <class 'v1.Lexer.Components.Tokens.DedentToken.MatchResult'>
          {}
      phrase: "Dedent"
  phrase: "Indent"
iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
  begin: "[10, 1] (123)"
  end: "[13, 1] (210)"
success: True
