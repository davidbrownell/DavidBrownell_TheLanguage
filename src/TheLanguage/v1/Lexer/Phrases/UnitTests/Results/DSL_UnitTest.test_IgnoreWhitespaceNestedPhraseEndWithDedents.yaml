# <class 'v1.Lexer.Components.Phrase.Phrase.LexResult'>
data: # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
  data:
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: False
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[1, 1] (0)"
          end: "[1, 9] (8)"
        token: "Word Token"
        value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
          match: "<_sre.SRE_Match object; span=(0, 8), match='newscope'>"
      phrase: "Word Token"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: False
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[1, 9] (8)"
          end: "[1, 10] (9)"
        token: "':'"
        value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
          match: "<_sre.SRE_Match object; span=(8, 9), match=':'>"
      phrase: "':'"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: False
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[1, 10] (9)"
          end: "[4, 1] (12)"
        token: "Newline+"
        value: # <class 'v1.Lexer.Components.Tokens.NewlineToken.MatchResult'>
          range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
            begin: 9
            end: 12
      phrase: "Newline+"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: False
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[4, 1] (12)"
          end: "[4, 5] (16)"
        token: "Indent"
        value: # <class 'v1.Lexer.Components.Tokens.IndentToken.MatchResult'>
          indent_value: 4
          range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
            begin: 12
            end: 16
      phrase: "Indent"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data:
        - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
          data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
            is_ignored: False
            iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
              begin: "[4, 5] (16)"
              end: "[4, 10] (21)"
            token: "Word Token"
            value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
              match: "<_sre.SRE_Match object; span=(16, 21), match='worda'>"
          phrase: "Word Token"
        - # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
          is_ignored: True
          iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
            begin: "[4, 10] (21)"
            end: "[5, 1] (22)"
          token: "Newline+"
          value: # <class 'v1.Lexer.Components.Tokens.NewlineToken.MatchResult'>
            range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
              begin: 21
              end: 22
        - # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
          is_ignored: True
          iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
            begin: "[5, 1] (22)"
            end: "[5, 9] (30)"
          token: "Indent"
          value: # <class 'v1.Lexer.Components.Tokens.IndentToken.MatchResult'>
            indent_value: 8
            range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
              begin: 22
              end: 30
        - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
          data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
            is_ignored: False
            iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
              begin: "[5, 9] (30)"
              end: "[5, 14] (35)"
            token: "Word Token"
            value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
              match: "<_sre.SRE_Match object; span=(30, 35), match='wordb'>"
          phrase: "Word Token"
        - # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
          is_ignored: True
          iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
            begin: "[5, 14] (35)"
            end: "[8, 1] (38)"
          token: "Newline+"
          value: # <class 'v1.Lexer.Components.Tokens.NewlineToken.MatchResult'>
            range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
              begin: 35
              end: 38
        - # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
          is_ignored: True
          iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
            begin: "[8, 1] (38)"
            end: "[8, 1] (38)"
          token: "Dedent"
          value: # <class 'v1.Lexer.Components.Tokens.DedentToken.MatchResult'>
            {}
      phrase: "Nested"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: False
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[8, 1] (38)"
          end: "[8, 1] (38)"
        token: "Dedent"
        value: # <class 'v1.Lexer.Components.Tokens.DedentToken.MatchResult'>
          {}
      phrase: "Dedent"
  phrase: "Phrase"
iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
  begin: "[1, 1] (0)"
  end: "[8, 1] (38)"
success: True
