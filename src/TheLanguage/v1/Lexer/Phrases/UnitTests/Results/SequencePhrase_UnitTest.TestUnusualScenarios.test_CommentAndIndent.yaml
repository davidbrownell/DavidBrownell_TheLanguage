# <class 'v1.Lexer.Components.Phrase.Phrase.LexResult'>
data: # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
  data:
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: False
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[1, 1] (0)"
          end: "[1, 7] (6)"
        token: "lower"
        value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
          match: "<_sre.SRE_Match object; span=(0, 6), match='lower1'>"
      phrase: "lower"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: False
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[1, 7] (6)"
          end: "[2, 1] (7)"
        token: "Newline+"
        value: # <class 'v1.Lexer.Components.Tokens.NewlineToken.MatchResult'>
          range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
            begin: 6
            end: 7
      phrase: "Newline+"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: False
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[2, 1] (7)"
          end: "[2, 5] (11)"
        token: "Indent"
        value: # <class 'v1.Lexer.Components.Tokens.IndentToken.MatchResult'>
          indent_value: 4
          range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
            begin: 7
            end: 11
      phrase: "Indent"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: False
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[2, 5] (11)"
          end: "[2, 11] (17)"
        token: "upper"
        value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
          match: "<_sre.SRE_Match object; span=(11, 17), match='UPPER1'>"
      phrase: "upper"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: False
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[2, 11] (17)"
          end: "[4, 1] (19)"
        token: "Newline+"
        value: # <class 'v1.Lexer.Components.Tokens.NewlineToken.MatchResult'>
          range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
            begin: 17
            end: 19
      phrase: "Newline+"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: False
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[4, 1] (19)"
          end: "[4, 1] (19)"
        token: "Dedent"
        value: # <class 'v1.Lexer.Components.Tokens.DedentToken.MatchResult'>
          {}
      phrase: "Dedent"
  phrase: "[lower, Newline+, Indent, upper, Newline+, Dedent]"
iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
  begin: "[1, 1] (0)"
  end: "[4, 1] (19)"
success: True

# <class 'v1.Lexer.Components.Phrase.Phrase.LexResult'>
data: # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
  data:
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: False
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[4, 1] (19)"
          end: "[4, 7] (25)"
        token: "lower"
        value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
          match: "<_sre.SRE_Match object; span=(19, 25), match='lower2'>"
      phrase: "lower"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: False
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[4, 7] (25)"
          end: "[5, 1] (26)"
        token: "Newline+"
        value: # <class 'v1.Lexer.Components.Tokens.NewlineToken.MatchResult'>
          range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
            begin: 25
            end: 26
      phrase: "Newline+"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
      is_ignored: True
      iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
        begin: "[5, 1] (26)"
        end: "[5, 5] (30)"
      token: "HorizontalWhitespace"
      value: # <class 'v1.Lexer.Components.Tokens.HorizontalWhitespaceToken.MatchResult'>
        range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
          begin: 26
          end: 30
    - # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
      is_ignored: True
      iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
        begin: "[5, 5] (30)"
        end: "[5, 65] (90)"
      token: "<comment>"
      value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
        match: "<_sre.SRE_Match object; span=(30, 90), match='# This is a comment; it should not interfere with>"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
      is_ignored: True
      iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
        begin: "[5, 65] (90)"
        end: "[6, 1] (91)"
      token: "Newline+"
      value: # <class 'v1.Lexer.Components.Tokens.NewlineToken.MatchResult'>
        range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
          begin: 90
          end: 91
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: False
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[6, 1] (91)"
          end: "[6, 5] (95)"
        token: "Indent"
        value: # <class 'v1.Lexer.Components.Tokens.IndentToken.MatchResult'>
          indent_value: 4
          range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
            begin: 91
            end: 95
      phrase: "Indent"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: False
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[6, 5] (95)"
          end: "[6, 11] (101)"
        token: "upper"
        value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
          match: "<_sre.SRE_Match object; span=(95, 101), match='UPPER2'>"
      phrase: "upper"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: False
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[6, 11] (101)"
          end: "[7, 1] (102)"
        token: "Newline+"
        value: # <class 'v1.Lexer.Components.Tokens.NewlineToken.MatchResult'>
          range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
            begin: 101
            end: 102
      phrase: "Newline+"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: False
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[7, 1] (102)"
          end: "[7, 1] (102)"
        token: "Dedent"
        value: # <class 'v1.Lexer.Components.Tokens.DedentToken.MatchResult'>
          {}
      phrase: "Dedent"
  phrase: "[lower, Newline+, Indent, upper, Newline+, Dedent]"
iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
  begin: "[4, 1] (19)"
  end: "[7, 1] (102)"
success: True
