# <class 'v1.Lexer.Components.Phrase.Phrase.LexResult'>
data: # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
  data:
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data: []
      phrase: "{[Word Token, Newline+], 0, None}"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data:
        - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
          data:
            - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
              data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
                is_ignored: false
                iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
                  begin: "[1, 1] (0)"
                  end: "[1, 3] (2)"
                token: "Number Token"
                value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
                  match: "<_sre.SRE_Match object; span=(0, 2), match='12'>"
              phrase: "Number Token"
            - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
              data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
                is_ignored: false
                iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
                  begin: "[1, 3] (2)"
                  end: "[2, 1] (3)"
                token: "Newline+"
                value: # <class 'v1.Lexer.Components.Tokens.NewlineToken.MatchResult'>
                  range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
                    begin: 2
                    end: 3
              phrase: "Newline+"
          phrase: "[Number Token, Newline+]"
        - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
          data:
            - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
              data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
                is_ignored: false
                iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
                  begin: "[2, 1] (3)"
                  end: "[2, 5] (7)"
                token: "Number Token"
                value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
                  match: "<_sre.SRE_Match object; span=(3, 7), match='3456'>"
              phrase: "Number Token"
            - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
              data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
                is_ignored: false
                iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
                  begin: "[2, 5] (7)"
                  end: "[3, 1] (8)"
                token: "Newline+"
                value: # <class 'v1.Lexer.Components.Tokens.NewlineToken.MatchResult'>
                  range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
                    begin: 7
                    end: 8
              phrase: "Newline+"
          phrase: "[Number Token, Newline+]"
      phrase: "{[Number Token, Newline+], 1, None}"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data:
        - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
          data:
            - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
              data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
                is_ignored: false
                iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
                  begin: "[3, 1] (8)"
                  end: "[3, 6] (13)"
                token: "Upper Token"
                value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
                  match: "<_sre.SRE_Match object; span=(8, 13), match='UPPER'>"
              phrase: "Upper Token"
            - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
              data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
                is_ignored: false
                iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
                  begin: "[3, 6] (13)"
                  end: "[4, 1] (14)"
                token: "Newline+"
                value: # <class 'v1.Lexer.Components.Tokens.NewlineToken.MatchResult'>
                  range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
                    begin: 13
                    end: 14
              phrase: "Newline+"
          phrase: "[Upper Token, Newline+]"
      phrase: "{[Upper Token, Newline+], 0, 1}"
    - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
      data:
        - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
          data:
            - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
              data: null
              phrase: "Word Token"
          phrase: "[Word Token, Newline+]"
      phrase: "{[Word Token, Newline+], 1, None}"
  phrase: "[{[Word Token, Newline+], 0, None}, {[Number Token, Newline+], 1, None}, {[Upper Token, Newline+], 0, 1}, {[Word Token, Newline+], 1, None}]"
iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
  begin: "[1, 1] (0)"
  end: "[4, 1] (14)"
success: false
