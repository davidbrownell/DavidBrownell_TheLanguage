# <class 'v1.Lexer.Components.Phrase.Phrase.LexResult'>
data: # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
  data: # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
    data:
      - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
        data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
          is_ignored: False
          iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
            begin: "[1, 1] (0)"
            end: "[1, 7] (6)"
          token: "lower"
          value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
            match: "<_sre.SRE_Match object; span=(0, 6), match='lower1'>"
        phrase: "lower"
      - # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: True
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[1, 7] (6)"
          end: "[1, 8] (7)"
        token: "HorizontalWhitespace"
        value: # <class 'v1.Lexer.Components.Tokens.HorizontalWhitespaceToken.MatchResult'>
          range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
            begin: 6
            end: 7
      - # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: True
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[1, 7] (6)"
          end: "[1, 18] (17)"
        token: "<comment>"
        value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
          match: "<_sre.SRE_Match object; span=(7, 17), match='# Comment2'>"
      - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
        data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
          is_ignored: False
          iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
            begin: "[1, 18] (17)"
            end: "[2, 1] (18)"
          token: "Newline+"
          value: # <class 'v1.Lexer.Components.Tokens.NewlineToken.MatchResult'>
            range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
              begin: 17
              end: 18
        phrase: "Newline+"
    phrase: "[lower, Newline+]"
  phrase: "([lower, Newline+] | [upper, Newline+])"
iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
  begin: "[1, 1] (0)"
  end: "[2, 1] (18)"
success: True

# <class 'v1.Lexer.Components.Phrase.Phrase.LexResult'>
data: # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
  data: # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
    data:
      - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
        data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
          is_ignored: False
          iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
            begin: "[2, 1] (18)"
            end: "[2, 7] (24)"
          token: "lower"
          value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
            match: "<_sre.SRE_Match object; span=(18, 24), match='lower2'>"
        phrase: "lower"
      - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
        data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
          is_ignored: False
          iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
            begin: "[2, 7] (24)"
            end: "[3, 1] (25)"
          token: "Newline+"
          value: # <class 'v1.Lexer.Components.Tokens.NewlineToken.MatchResult'>
            range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
              begin: 24
              end: 25
        phrase: "Newline+"
    phrase: "[lower, Newline+]"
  phrase: "([lower, Newline+] | [upper, Newline+])"
iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
  begin: "[2, 1] (18)"
  end: "[3, 1] (25)"
success: True

# <class 'v1.Lexer.Components.Phrase.Phrase.LexResult'>
data: # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
  data: # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
    data:
      - # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: True
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[3, 1] (25)"
          end: "[3, 11] (35)"
        token: "<comment>"
        value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
          match: "<_sre.SRE_Match object; span=(25, 35), match='# Comment3'>"
      - # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: True
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[3, 11] (35)"
          end: "[4, 1] (36)"
        token: "Newline+"
        value: # <class 'v1.Lexer.Components.Tokens.NewlineToken.MatchResult'>
          range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
            begin: 35
            end: 36
      - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
        data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
          is_ignored: False
          iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
            begin: "[4, 1] (36)"
            end: "[4, 7] (42)"
          token: "lower"
          value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
            match: "<_sre.SRE_Match object; span=(36, 42), match='lower3'>"
        phrase: "lower"
      - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
        data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
          is_ignored: False
          iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
            begin: "[4, 7] (42)"
            end: "[8, 1] (46)"
          token: "Newline+"
          value: # <class 'v1.Lexer.Components.Tokens.NewlineToken.MatchResult'>
            range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
              begin: 42
              end: 46
        phrase: "Newline+"
    phrase: "[lower, Newline+]"
  phrase: "([lower, Newline+] | [upper, Newline+])"
iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
  begin: "[3, 1] (25)"
  end: "[8, 1] (46)"
success: True

# <class 'v1.Lexer.Components.Phrase.Phrase.LexResult'>
data: # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
  data: # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
    data:
      - # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: True
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[8, 5] (50)"
          end: "[8, 15] (60)"
        token: "<comment>"
        value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
          match: "<_sre.SRE_Match object; span=(50, 60), match='# Comment4'>"
      - # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: True
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[8, 15] (60)"
          end: "[9, 1] (61)"
        token: "Newline+"
        value: # <class 'v1.Lexer.Components.Tokens.NewlineToken.MatchResult'>
          range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
            begin: 60
            end: 61
      - # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: True
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[9, 1] (61)"
          end: "[9, 11] (71)"
        token: "<comment>"
        value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
          match: "<_sre.SRE_Match object; span=(61, 71), match='# Comment5'>"
      - # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
        is_ignored: True
        iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
          begin: "[9, 11] (71)"
          end: "[12, 1] (74)"
        token: "Newline+"
        value: # <class 'v1.Lexer.Components.Tokens.NewlineToken.MatchResult'>
          range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
            begin: 71
            end: 74
      - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
        data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
          is_ignored: False
          iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
            begin: "[12, 1] (74)"
            end: "[12, 7] (80)"
          token: "lower"
          value: # <class 'v1.Lexer.Components.Tokens.RegexToken.MatchResult'>
            match: "<_sre.SRE_Match object; span=(74, 80), match='lower4'>"
        phrase: "lower"
      - # <class 'v1.Lexer.Components.Phrase.Phrase.LexResultData'>
        data: # <class 'v1.Lexer.Components.Phrase.Phrase.TokenLexResultData'>
          is_ignored: False
          iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
            begin: "[12, 7] (80)"
            end: "[13, 1] (81)"
          token: "Newline+"
          value: # <class 'v1.Lexer.Components.Tokens.NewlineToken.MatchResult'>
            range: # <class 'v1.Lexer.Components.Normalize.OffsetRange'>
              begin: 80
              end: 81
        phrase: "Newline+"
    phrase: "[lower, Newline+]"
  phrase: "([lower, Newline+] | [upper, Newline+])"
iter_range: # <class 'v1.Lexer.Components.Phrase.Phrase.NormalizedIteratorRange'>
  begin: "[8, 1] (46)"
  end: "[13, 1] (81)"
success: True
